---
title: "sequence_prep_tidy"
author: "Dominik"
date: "2024-04-08"
output: html_document
---

This code chunk ensures that all the necessary R packages for sequencing data analysis are installed and up-to-date. It first checks for the presence of `BiocManager`, installs it if missing, and then uses it to install the `dada2` package for accurate sample inference from amplicon data, and `Rcpp` for seamless R and C++ integration. The `force = TRUE` option in `BiocManager::install` ensures the latest version of `dada2` is installed, even if it's already present.

```{r}
if (!require("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install(version = "3.18")

BiocManager::install("dada2", force =T)
install.packages("Rcpp")
```

This chunk loads the previously installed libraries into the R session, making their functions available for use. `Rcpp` is essential for high-performance statistical computing, `dada2` is specialized for high-resolution sample inference from sequencing data, and `ggplot2` offers versatile plotting capabilities for data visualization.
```{r}
library("Rcpp")
library("dada2")
library("ggplot2")
```

Workspace Setup and Sample Initialization
Here, we set the working directory to the location of the sequencing data and scripts. The `list.files()` function lists all files in the directory, aiding in verification. We then read sample names from a file, preparing the sequence filenames for analysis and setting the stage for data preprocessing by creating paths for both raw and filtered reads.

```{r}
setwd("/directory where the files are downloaded")##change directory here
list.files()

samples <- scan("samples", what = "character")

reads <- paste0(samples, "_joined-SR.fastq.bz2")
#make directories for the filtered files
filtered_reads <- paste0(samples, "_filtered.fastq.bz2")
```

This segment first visualizes the quality of unfiltered sequencing reads, providing insights into potential issues. It then applies filtering criteria to improve data quality, such as removing low-quality reads and PhiX contamination, and truncating reads to a uniform length. Post-filtering, the quality is reassessed through plots, and an error model is generated to understand the types and frequencies of sequencing errors.

```{r}
p_quality_unfiltered<- plotQualityProfile(reads)
ggsave("Quality_samples_unfiltered.png", p_quality_unfiltered, dpi = 300, width = 18, height = 14)

# the filtered_out object is a table which shows how many reads were filtered out and how many were there in the first place
filtered_out <- filterAndTrim(reads, filtered_reads, maxEE=2,
                              rm.phix=TRUE, minLen=170, truncLen = 350)

#show the quality of the filtered samples
p_quality_filtered <- plotQualityProfile(filtered_reads)

ggsave("Quality_samples_filtered.png", p_quality_filtered, dpi = 300, width = 18, height = 14)

err_reads <- learnErrors(filtered_reads)
p_error_rates <- plotErrors(err_reads, nominalQ = T)
ggsave("Error_rates.png", p_error_rates, dpi = 300, width = 18, height = 14)
```

This step performs dereplication, a process of aggregating identical reads into unique sequences, thereby reducing computational complexity and memory usage. It prepares the data for the DADA2 algorithm by creating a list of dereplicated reads. The `dada` function is then applied with pooling enabled (`pool = TRUE`), which combines all samples to improve error rate estimation and sequence variant detection, maximizing the data utility and accuracy of the dataset.
```{r}

derep_reads <- derepFastq(filtered_reads, verbose = T)
names(derep_reads) <- samples
```

Due to the computationally intensive nature of the DADA2 pooling operation, it's isolated in this separate chunk. Pooling across all samples can significantly enhance sequence variant detection accuracy but requires considerable processing time, potentially running for an extended period. This isolation helps in managing runtime expectations and debugging, if necessary.
```{r}

dada_reads_Pool <- dada(derep_reads, err = err_reads, pool = T)

```

After sequence variant identification, this chunk compiles a sequence table, which organizes sequence variants by sample, facilitating downstream analyses. Following this, chimeric sequences — artifacts of PCR that can bias analyses — are identified and removed. This process ensures the dataset comprises only biological sequences, enhancing the accuracy of subsequent taxonomic assignment and abundance estimation.

```{r}

sequences_Pool <- makeSequenceTable(dada_reads_Pool)

dada_reads_nc_Pool <- removeBimeraDenovo(sequences_Pool, verbose = T)

names(dada_reads_nc_Pool)

```

In preparation for taxonomic assignment, this chunk loads a comprehensive SILVA reference database, essential for accurately matching our sequences to known species. Additionally, the `DECIPHER` package is loaded, Sequences are prepared with the DNAStringSet() function fur further application.
```{r}
load("SILVA_SSU_r138_2019.RData")

## loading DECIPHER
library(DECIPHER)
packageVersion("DECIPHER") # v2.6.0 when this was initially put together, though might be different in the binder or conda installation, that's ok!

dna_pool <- DNAStringSet(getSequences(dada_reads_nc_Pool))

```

Utilizing the `IDTaxa` function from the DECIPHER package, this section assigns taxonomic classifications to each sequence variant based on the loaded SILVA reference database. The taxonomy for each sequence variant is resolved down to the species level where possible. The results are then organized into a comprehensive taxonomy table, detailing the classified taxonomic ranks for each sequence variant. This table is saved as "ASVs_taxonomy.tsv" it contains the taxonomic data of the found ASVs

```{r}
tax_info <- IdTaxa(test=dna_pool, trainingSet=trainingSet, strand="both", processors=NULL)

asv_seqs <- colnames(dada_reads_nc_Pool)
asv_headers <- vector(dim(dada_reads_nc_Pool)[2], mode="character")

ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species")
asv_tax <- t(sapply(tax_info, function(x) {
  m <- match(ranks, x$rank)
  taxa <- x$taxon[m]
  taxa[startsWith(taxa, "unclassified_")] <- NA
  taxa
}))

colnames(asv_tax) <- ranks
rownames(asv_tax) <- gsub(pattern=">", replacement="", x=asv_headers)

write.table(asv_tax, "ASVs_taxonomy.tsv", sep = "\t", quote=F, col.names=NA)

```

The final step in the preprocessing pipeline involves generating a count table, which quantifies the abundance of each sequence variant across all samples. This table is crucial for downstream quantitative analyses, such as diversity assessments and comparative studies among samples. Sequence variants are uniquely labeled, and their counts across samples are tabulated, providing a clear view of the community structure and abundance within the dataset.The tabe is saves as "ASVs_counts.tsv" in the working directory. 
```{r}

for (i in 1:dim(dada_reads_nc_Pool)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep="_")
}
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, "ASVs.fa")
asv_tab <- t(dada_reads_nc_Pool)
row.names(asv_tab) <- sub(">", "", asv_headers)

write.table(asv_tab, "ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)
```
